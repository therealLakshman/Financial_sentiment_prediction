{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b75b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab57edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting tracking \n",
    "mlflow.set_tracking_uri(\"http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692477db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name :baseline_ML_model and id:408458959843314322\n",
      "Experiment name :Navie_bayes_experiment and id:639483181163671325\n",
      "Experiment name :Default and id:0\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient \n",
    "client = MlflowClient()\n",
    "\n",
    "# Get all experiments (returns List[Experiment])\n",
    "experiments_id = client.search_experiments()\n",
    "\n",
    "for exp in experiments_id:\n",
    "    print(f\"Experiment name :{exp.name} and id:{exp.experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f013f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment not found.\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"ML_model_dataaug\"\n",
    "\n",
    "# Get the experiment (even if soft-deleted)\n",
    "exp = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "if exp:\n",
    "    runs = client.search_runs(exp.experiment_id)\n",
    "    print(f\"Found {len(runs)} runs in experiment '{experiment_name}' (status: {exp.lifecycle_stage})\")\n",
    "else:\n",
    "    print(\"Experiment not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3093bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 15:57:53 INFO mlflow.tracking.fluent: Experiment with name 'ML_model_dataaug' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://s3bucmlflow/918242205499858319', creation_time=1757413674527, experiment_id='918242205499858319', last_update_time=1757413674527, lifecycle_stage='active', name='ML_model_dataaug', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=\"ML_model_dataaug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dbcec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/root/mlops_projects/FinancialSentiment_prediction/Datasets/Financial_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07128170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...   neutral\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...   neutral\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea28e337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(520)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9d2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep=\"first\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d3c4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba4cfd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced text preprocessing for financial sentiment\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # Retain numbers and basic punctuation, remove only special characters\n",
    "    text = re.sub(r'http\\S+|[^\\w\\s.]', '', text)  # Keep numbers, commas, periods\n",
    "    text = re.sub(r'\\s+',' ',text) #collapsing multiple spaces to one space\n",
    "    #text = text.strip() #removes white spaces\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    stop_words = set(stopwords.words('english')) - {'not', 'no', 'never', 'very', 'bullish', 'bearish', 'buy', 'sell', 'strong', 'weak', 'profit', 'loss', 'growth'}\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc41429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentence\"] = df[\"Sentence\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51287c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"Sentence\"]\n",
    "y = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d0f46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_con(data):\n",
    "    res = data.map(lambda x: 1 if x == \"positive\" else (0 if x == \"neutral\" else -1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26dae656",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_con(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b632d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1      -1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "5835    0\n",
      "5836    0\n",
      "5838    0\n",
      "5839    0\n",
      "5841    0\n",
      "Name: Sentiment, Length: 5322, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e53d92c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5322,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a9b10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f87464f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1], shape=(3991,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60ab2d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id for ML_model_dataaug is :918242205499858319\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"ML_model_dataaug\"\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(name=experiment_name)\n",
    "    experiment_Id = experiment.experiment_id\n",
    "    print(f\"experiment_id for {experiment_name} is :{experiment_Id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baa9e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "#import nlpaug.augmenter.sentence as nas\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83666916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1378/1378 [00:01<00:00, 1076.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmented. Total samples: 5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize augmenter\n",
    "aug = naw.SynonymAug(aug_src='wordnet', \n",
    "                     lang='eng', \n",
    "                     aug_p=0.4, \n",
    "                     aug_max=5)\n",
    "# Ensure indices are properly aligned\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "# Get indices of samples to augment (sentiment 0 or 2)\n",
    "indices = y_train[y_train.isin([-1, 1])].index\n",
    "augmented = []\n",
    "\n",
    "for idx in tqdm(indices, desc=\"Augmenting\"):\n",
    "    try:\n",
    "        # Access sentence (Series: x_train.loc[idx], DataFrame: x_train.loc[idx, 'Sentence'])\n",
    "        sentence = x_train.loc[idx] if isinstance(x_train, pd.Series) else x_train.loc[idx, 'Sentence']\n",
    "        sentiment = y_train.loc[idx]\n",
    "        \n",
    "        new_text = aug.augment(sentence)\n",
    "        if isinstance(new_text,list):\n",
    "            new_text = \"\".join(new_text)\n",
    "        augmented.append({'Sentence': new_text, \n",
    "                          'Sentiment': sentiment,\n",
    "                          \"Source\": \"Augmented\"})\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping index {idx}: {str(e)}\")\n",
    "\n",
    "# Combine with original data\n",
    "if augmented:\n",
    "    aug_df = pd.DataFrame(augmented)\n",
    "    \n",
    "    # Handle x_train (Series or DataFrame)\n",
    "    original_df = pd.DataFrame({\"Sentence\" : x_train, \n",
    "                            \"Sentiment\" : y_train, \n",
    "                            \"Source\" : \"Original\"})\n",
    "    \n",
    "    combined_df = pd.concat([original_df,aug_df],ignore_index=True)\n",
    "\n",
    "    # Shuffle rows (frac=1 means \"return all rows in random order\")\n",
    "    df_final = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "\n",
    "    #update x_train and y_train\n",
    "    x_train = df_final[\"Sentence\"]\n",
    "    # Always treat y_train as Series\n",
    "    y_train = df_final[\"Sentiment\"]\n",
    "    \n",
    "    print(f\"Data augmented. Total samples: {len(x_train)}\")\n",
    "else:\n",
    "    print(\"No augmentations added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20bffce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       " 0    2613\n",
       " 1    2190\n",
       "-1     566\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51d542ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5369,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b6cc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model_with_tuning(model_class, model_name, vectorizer_type,\n",
    "                                    x_train, x_test, y_train, y_test,\n",
    "                                    experiment_id, param_distributions,\n",
    "                                    n_iter_search, cv_folds, scoring_metric):\n",
    "    \"\"\"\n",
    "    Trains and logs a model after performing RandomizedSearchCV for hyperparameter tuning.\n",
    "    The best model from the search is logged.\n",
    "    \"\"\"\n",
    "    run_name_prefix = f\"{model_name}-{vectorizer_type}-Tuning\"\n",
    "\n",
    "    x_train = x_train.astype(str).fillna('')\n",
    "    x_test = x_test.astype(str).fillna('')\n",
    "\n",
    "    if model_class == XGBClassifier: #as classifier not accept negative labels\n",
    "        y_train = y_train.map({0:0,1:1,-1:2})\n",
    "        y_test  = y_test.map({0:0,1:1,-1:2})\n",
    "\n",
    "    # Define the base vectorizer based on type\n",
    "    if vectorizer_type == \"bow\":\n",
    "        vectorizer_instance = CountVectorizer()\n",
    "    elif vectorizer_type == \"tfidf\":\n",
    "        vectorizer_instance = TfidfVectorizer()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid vectorizer type\")\n",
    "\n",
    "    # Instantiate the classifier\n",
    "    if model_class == XGBClassifier:\n",
    "        classifier_instance = XGBClassifier(\n",
    "            #use_label_encoder=False,  # Recommended to suppress future warnings\n",
    "            eval_metric='mlogloss',   # Multi-class logloss for multi-class classification\n",
    "            objective='multi:softmax', # For direct class predictions\n",
    "            num_class=len(y.unique()), # Important: Set number of classes\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        classifier_instance = model_class(random_state=42) # Setting random_state for reproducibility\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer_instance),\n",
    "        ('classifier', classifier_instance)\n",
    "    ])\n",
    "\n",
    "    # Initialize RandomizedSearchCV\n",
    "    # We pass the pipeline here, and the param_distributions should be prefixed\n",
    "    # e.g., 'classifier__n_estimators'\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter_search,\n",
    "        cv=cv_folds,\n",
    "        scoring=scoring_metric,\n",
    "        random_state=42, # For reproducible search results\n",
    "        n_jobs=1, #\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"\\nStarting RandomizedSearchCV for {model_name} with {vectorizer_type}...\")\n",
    "    random_search.fit(x_train, y_train)\n",
    "\n",
    "    # Get the best model found by the search\n",
    "    best_pipeline = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "\n",
    "    # Make predictions with the best model\n",
    "    y_pred = best_pipeline.predict(x_test)\n",
    "\n",
    "    # Calculate final metrics on the test set\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Start MLflow run for logging the BEST model from the search\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=f\"{run_name_prefix}-BestModel\"):\n",
    "\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"vectorizer_type\", vectorizer_type)\n",
    "        mlflow.log_param(\"tuning_method\", \"RandomizedSearchCV\")\n",
    "        mlflow.log_param(\"n_iter_search\", n_iter_search)\n",
    "        mlflow.log_param(\"cv_folds\", cv_folds)\n",
    "        mlflow.log_param(\"scoring_metric\", scoring_metric)\n",
    "\n",
    "        # Log all best parameters found by the search\n",
    "        for k, v in best_params.items():\n",
    "            mlflow.log_param(k, v)\n",
    "\n",
    "        # Log metrics (best CV score and test set performance)\n",
    "        mlflow.log_metric(f\"best_cv_{scoring_metric}\", best_score)\n",
    "        mlflow.log_metric(\"test_accuracy\", acc)\n",
    "        mlflow.log_metric(\"test_f1_score_weighted\", f1)\n",
    "\n",
    "         # Directly log the full classification report as a text file\n",
    "        full_report_str = classification_report(y_test, y_pred)\n",
    "        mlflow.log_text(full_report_str, \"classification_report.txt\")\n",
    "\n",
    "        print(\"\\nClassification Report:\\n\", full_report_str)\n",
    "\n",
    "\n",
    "\n",
    "        # Log vectorizer specific parameters (from the best pipeline's vectorizer)\n",
    "        best_vectorizer = best_pipeline.named_steps['vectorizer']\n",
    "        mlflow.log_param(\"vectorizer_vocab_size\", len(best_vectorizer.vocabulary_))\n",
    "        if hasattr(best_vectorizer, \"get_params\"):\n",
    "            for k, v in best_vectorizer.get_params().items():\n",
    "                # Filter out parameters that aren't typically interesting to log at top level\n",
    "                if not (k.startswith(\"input\") or k.startswith(\"dtype\")):\n",
    "                    mlflow.log_param(f\"vectorizer_{k}\", v)\n",
    "\n",
    "\n",
    "        # Log the entire best pipeline\n",
    "        # Signature for the entire pipeline: Input is raw text, Output is prediction\n",
    "        pipeline_input_example = x_train[:2].astype('str').fillna('').to_list() # Ensure input example is raw text\n",
    "        pipeline_output_example = best_pipeline.predict(pipeline_input_example)\n",
    "        pipeline_signature = infer_signature(pipeline_input_example, pipeline_output_example)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_pipeline,\n",
    "            name= \"text_classification_pipeline\",\n",
    "            signature=pipeline_signature,\n",
    "            input_example=pipeline_input_example\n",
    "        )\n",
    "\n",
    "        print(f\"\\n--- Best Model from Tuning ---\")\n",
    "        print(f\"Model: {model_name}, Vectorizer: {vectorizer_type}\")\n",
    "        print(f\"Best CV Score ({scoring_metric}): {best_score:.4f}\")\n",
    "        print(f\"Test Accuracy: {acc:.4f}, Test F1 Score (weighted): {f1:.4f}\")\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"MLflow Run ID: {mlflow.active_run().info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfb7aefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest parameters \n",
    "rf_param_distributions_bow = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 1.0, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'classifier__n_estimators': [100, 200, 300, 500],\n",
    "    'classifier__max_depth': [10, 20, 30, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rf_param_distributions_tfidf = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 1.0, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__use_idf': [True, False],\n",
    "    'classifier__n_estimators': [100, 250, 400],\n",
    "    'classifier__max_depth': [15, 25, None],\n",
    "    'classifier__min_samples_split': [2, 5, 8],\n",
    "    'classifier__min_samples_leaf': [1, 2, 3],\n",
    "    'classifier__max_features': ['sqrt', 0.6, 0.8],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "227fa044",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_distributions_tfidf = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 1.0, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2),(1,3)],        \n",
    "    'classifier__C': np.logspace(-3, 2, 6), # Example: 0.001, 0.01, 0.1, 1, 10, 100\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear','lbfgs', 'saga'], # Solvers supporting l1/l2\n",
    "    'classifier__max_iter': [100, 200, 500], # Increase if convergence warnings appear\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "lr_param_distributions_bow = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 1.0, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],         \n",
    "    'classifier__C': np.logspace(-4, 3, 8), # Broader range for C\n",
    "    'classifier__penalty': ['l2'], # Common choice for Logistic Regression\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg', 'sag'], # Solvers supporting only l2\n",
    "    'classifier__max_iter': [100, 300, 1000],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "454c76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_distributions_bow = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 0.99, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__subsample': [0.7, 0.9],\n",
    "    'classifier__colsample_bytree': [0.7, 0.9],\n",
    "    'classifier__gamma': [0, 0.1, 0.2] # Min loss reduction to make a split\n",
    "}\n",
    "\n",
    "xgb_param_distributions_tf_idf = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 0.99, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__use_idf': [True, False], # Important for TF-IDF\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__subsample': [0.7, 0.9],\n",
    "    'classifier__colsample_bytree': [0.7, 0.9],\n",
    "    'classifier__gamma': [0, 0.1, 0.2] # Min loss reduction to make a split\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14ba8051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Random Forest Tuning ---\n",
      "\n",
      "Starting RandomizedSearchCV for RandomForestClassifier with bow...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.59      0.67        94\n",
      "           0       0.86      0.95      0.90       871\n",
      "           1       0.89      0.73      0.80       366\n",
      "\n",
      "    accuracy                           0.86      1331\n",
      "   macro avg       0.85      0.76      0.79      1331\n",
      "weighted avg       0.87      0.86      0.86      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 16:08:43 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"poyry plc additional informat.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: RandomForestClassifier, Vectorizer: bow\n",
      "Best CV Score (f1_weighted): 0.7850\n",
      "Test Accuracy: 0.8648, Test F1 Score (weighted): 0.8602\n",
      "Best Parameters: {'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 5, 'vectorizer__max_df': np.float64(0.75), 'classifier__n_estimators': 500, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 30, 'classifier__class_weight': 'balanced'}\n",
      "MLflow Run ID: 7357223ab46643dcbf76ebf6934927a4\n",
      "ðŸƒ View run RandomForestClassifier-bow-Tuning-BestModel at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319/runs/7357223ab46643dcbf76ebf6934927a4\n",
      "ðŸ§ª View experiment at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Running Random Forest Tuning ---\")\n",
    "train_and_log_model_with_tuning(\n",
    "    model_class=RandomForestClassifier,\n",
    "    model_name=\"RandomForestClassifier\",\n",
    "    vectorizer_type=\"bow\",\n",
    "    x_train=x_train, y_train=y_train,\n",
    "    x_test=x_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=rf_param_distributions_bow,\n",
    "    n_iter_search=5, \n",
    "    cv_folds=5,      \n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07e21874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for RandomForestClassifier with tfidf...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.57      0.57        94\n",
      "           0       0.88      0.90      0.89       871\n",
      "           1       0.84      0.79      0.82       366\n",
      "\n",
      "    accuracy                           0.85      1331\n",
      "   macro avg       0.76      0.76      0.76      1331\n",
      "weighted avg       0.85      0.85      0.85      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 16:18:14 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"poyry plc additional informat.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: RandomForestClassifier, Vectorizer: tfidf\n",
      "Best CV Score (f1_weighted): 0.8127\n",
      "Test Accuracy: 0.8490, Test F1 Score (weighted): 0.8487\n",
      "Best Parameters: {'vectorizer__use_idf': True, 'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 10, 'vectorizer__max_df': np.float64(0.75), 'classifier__n_estimators': 250, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 3, 'classifier__max_features': 0.6, 'classifier__max_depth': None, 'classifier__class_weight': 'balanced'}\n",
      "MLflow Run ID: 55ea5d9c60534d6f86a7592d0a0b111d\n",
      "ðŸƒ View run RandomForestClassifier-tfidf-Tuning-BestModel at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319/runs/55ea5d9c60534d6f86a7592d0a0b111d\n",
      "ðŸ§ª View experiment at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=RandomForestClassifier,\n",
    "    model_name=\"RandomForestClassifier\",\n",
    "    vectorizer_type=\"tfidf\",\n",
    "    x_train=x_train, y_train=y_train,\n",
    "    x_test=x_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=rf_param_distributions_tfidf,\n",
    "    n_iter_search=5,\n",
    "    cv_folds=5,\n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47e65d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for LogisticRegression with bow...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.51      0.61        94\n",
      "           0       0.85      0.95      0.90       871\n",
      "           1       0.89      0.73      0.80       366\n",
      "\n",
      "    accuracy                           0.86      1331\n",
      "   macro avg       0.83      0.73      0.77      1331\n",
      "weighted avg       0.86      0.86      0.85      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 16:20:19 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"poyry plc additional informat.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: LogisticRegression, Vectorizer: bow\n",
      "Best CV Score (f1_weighted): 0.8959\n",
      "Test Accuracy: 0.8573, Test F1 Score (weighted): 0.8517\n",
      "Best Parameters: {'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 1, 'vectorizer__max_df': np.float64(0.8500000000000001), 'classifier__solver': 'lbfgs', 'classifier__penalty': 'l2', 'classifier__max_iter': 100, 'classifier__class_weight': 'balanced', 'classifier__C': np.float64(10.0)}\n",
      "MLflow Run ID: 2cf09150f5e84f449176605483f3c45e\n",
      "ðŸƒ View run LogisticRegression-bow-Tuning-BestModel at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319/runs/2cf09150f5e84f449176605483f3c45e\n",
      "ðŸ§ª View experiment at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=LogisticRegression,\n",
    "    model_name=\"LogisticRegression\",\n",
    "    vectorizer_type=\"bow\",\n",
    "    x_train=x_train, y_train=y_train,\n",
    "    x_test=x_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=lr_param_distributions_bow,\n",
    "    n_iter_search=10,\n",
    "    cv_folds=5,\n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "106fb236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for LogisticRegression with tfidf...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "35 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/pipeline.py\", line 655, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/pipeline.py\", line 589, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\", line 2104, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got np.float64(1.0000000000000002) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.65972538        nan\n",
      " 0.78193574        nan 0.60530028        nan]\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.48      0.44        94\n",
      "           0       0.87      0.80      0.84       871\n",
      "           1       0.69      0.80      0.74       366\n",
      "\n",
      "    accuracy                           0.78      1331\n",
      "   macro avg       0.66      0.69      0.67      1331\n",
      "weighted avg       0.79      0.78      0.78      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 16:22:25 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"poyry plc additional informat.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: LogisticRegression, Vectorizer: tfidf\n",
      "Best CV Score (f1_weighted): 0.7819\n",
      "Test Accuracy: 0.7776, Test F1 Score (weighted): 0.7821\n",
      "Best Parameters: {'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 10, 'vectorizer__max_df': np.float64(0.7), 'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__max_iter': 500, 'classifier__class_weight': 'balanced', 'classifier__C': np.float64(10.0)}\n",
      "MLflow Run ID: faf0a817165448ae8259351bc30d11f8\n",
      "ðŸƒ View run LogisticRegression-tfidf-Tuning-BestModel at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319/runs/faf0a817165448ae8259351bc30d11f8\n",
      "ðŸ§ª View experiment at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=LogisticRegression,\n",
    "    model_name=\"LogisticRegression\",\n",
    "    vectorizer_type=\"tfidf\",\n",
    "    x_train=x_train, y_train=y_train,\n",
    "    x_test=x_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=lr_param_distributions_tfidf,\n",
    "    n_iter_search=10,\n",
    "    cv_folds=5,\n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b10104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for LogisticRegression with tfidf...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "35 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/pipeline.py\", line 655, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/pipeline.py\", line 589, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/feature_extraction/text.py\", line 2104, in fit_transform\n",
      "    X = super().fit_transform(raw_documents)\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_df' parameter of TfidfVectorizer must be a float in the range [0.0, 1.0] or an int in the range [1, inf). Got np.float64(1.0000000000000002) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.65972538        nan\n",
      " 0.78193574        nan 0.60530028        nan]\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.48      0.44        94\n",
      "           0       0.87      0.80      0.84       871\n",
      "           1       0.69      0.80      0.74       366\n",
      "\n",
      "    accuracy                           0.78      1331\n",
      "   macro avg       0.66      0.69      0.67      1331\n",
      "weighted avg       0.79      0.78      0.78      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 16:22:45 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"poyry plc additional informat.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: LogisticRegression, Vectorizer: tfidf\n",
      "Best CV Score (f1_weighted): 0.7819\n",
      "Test Accuracy: 0.7776, Test F1 Score (weighted): 0.7821\n",
      "Best Parameters: {'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 10, 'vectorizer__max_df': np.float64(0.7), 'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__max_iter': 500, 'classifier__class_weight': 'balanced', 'classifier__C': np.float64(10.0)}\n",
      "MLflow Run ID: 919eb9080d864d7f96d58629bb888bfc\n",
      "ðŸƒ View run LogisticRegression-tfidf-Tuning-BestModel at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319/runs/919eb9080d864d7f96d58629bb888bfc\n",
      "ðŸ§ª View experiment at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=LogisticRegression,\n",
    "    model_name=\"LogisticRegression\",\n",
    "    vectorizer_type=\"tfidf\",\n",
    "    x_train=x_train, y_train=y_train,\n",
    "    x_test=x_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=lr_param_distributions_tfidf,\n",
    "    n_iter_search=10,\n",
    "    cv_folds=5,\n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ba37707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for XGBoostClassifier with bow...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       871\n",
      "           1       0.92      0.78      0.84       366\n",
      "           2       0.86      0.54      0.67        94\n",
      "\n",
      "    accuracy                           0.88      1331\n",
      "   macro avg       0.88      0.76      0.81      1331\n",
      "weighted avg       0.88      0.88      0.88      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 16:31:08 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"poyry plc additional informat.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: XGBoostClassifier, Vectorizer: bow\n",
      "Best CV Score (f1_weighted): 0.8157\n",
      "Test Accuracy: 0.8820, Test F1 Score (weighted): 0.8773\n",
      "Best Parameters: {'vectorizer__ngram_range': (1, 3), 'vectorizer__min_df': 5, 'vectorizer__max_df': np.float64(0.7), 'classifier__subsample': 0.9, 'classifier__n_estimators': 100, 'classifier__max_depth': 7, 'classifier__learning_rate': 0.1, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.9}\n",
      "MLflow Run ID: 089a0509612e4053beba6c0429cbd26d\n",
      "ðŸƒ View run XGBoostClassifier-bow-Tuning-BestModel at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319/runs/089a0509612e4053beba6c0429cbd26d\n",
      "ðŸ§ª View experiment at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=XGBClassifier,\n",
    "    model_name=\"XGBoostClassifier\",\n",
    "    vectorizer_type=\"bow\",\n",
    "    x_train=x_train,\n",
    "    x_test=x_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    experiment_id=experiment_Id, # Use the obtained experiment_id\n",
    "    param_distributions= xgb_param_distributions_bow, #param_distributions,\n",
    "    n_iter_search=10, \n",
    "    cv_folds=5,      \n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfc6c2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for XGBoostClassifier with tfidf...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.91       871\n",
      "           1       0.93      0.77      0.84       366\n",
      "           2       0.84      0.52      0.64        94\n",
      "\n",
      "    accuracy                           0.88      1331\n",
      "   macro avg       0.88      0.75      0.80      1331\n",
      "weighted avg       0.88      0.88      0.88      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 16:26:56 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"poyry plc additional informat.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: XGBoostClassifier, Vectorizer: tfidf\n",
      "Best CV Score (f1_weighted): 0.7935\n",
      "Test Accuracy: 0.8813, Test F1 Score (weighted): 0.8760\n",
      "Best Parameters: {'vectorizer__use_idf': False, 'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 10, 'vectorizer__max_df': np.float64(0.8500000000000001), 'classifier__subsample': 0.9, 'classifier__n_estimators': 200, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.05, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.9}\n",
      "MLflow Run ID: b4db4060c54d476bb6892bcd1ed112c4\n",
      "ðŸƒ View run XGBoostClassifier-tfidf-Tuning-BestModel at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319/runs/b4db4060c54d476bb6892bcd1ed112c4\n",
      "ðŸ§ª View experiment at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/918242205499858319\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=XGBClassifier, \n",
    "    model_name=\"XGBoostClassifier\",\n",
    "    vectorizer_type=\"tfidf\",\n",
    "    x_train=x_train,\n",
    "    x_test=x_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    experiment_id=experiment_Id, # Use the obtained experiment_id\n",
    "    param_distributions= xgb_param_distributions_tf_idf, #param_distributions,\n",
    "    n_iter_search=10, \n",
    "    cv_folds=5,      \n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485dfee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_ops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
