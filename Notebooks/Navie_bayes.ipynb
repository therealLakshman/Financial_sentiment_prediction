{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689bc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8decebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB, GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e152e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting tracking \n",
    "mlflow.set_tracking_uri(\"http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdfc8220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:09:32 INFO mlflow.tracking.fluent: Experiment with name 'Navie_bayes_experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://s3bucmlflow/639483181163671325', creation_time=1757403573455, experiment_id='639483181163671325', last_update_time=1757403573455, lifecycle_stage='active', name='Navie_bayes_experiment', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"Navie_bayes_experiment\"\n",
    "mlflow.set_experiment(experiment_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd7c828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/root/mlops_projects/FinancialSentiment_prediction/Datasets/Financial_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530dc50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...   neutral\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...   neutral\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890ca596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5842, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812712e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "neutral     3747\n",
       "positive    1561\n",
       "negative     534\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee36391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "neutral     64.138993\n",
       "positive    26.720301\n",
       "negative     9.140705\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8837c524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>GSK joins China trade push as UK trumpets heal...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>The combined value of the orders is almost EUR...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>Our customers come from the following countrie...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>Simultaneously , Alma Media has purchased a 35...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>Alfa group will have 43.9 % of voting stock in...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "4792  GSK joins China trade push as UK trumpets heal...   neutral\n",
       "3139  The combined value of the orders is almost EUR...   neutral\n",
       "5179  Our customers come from the following countrie...   neutral\n",
       "5768  Simultaneously , Alma Media has purchased a 35...   neutral\n",
       "3435  Alfa group will have 43.9 % of voting stock in...  positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c890b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(520)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d42bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e62a6453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5322, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4a08412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x = df[\"Sentence\"]\n",
    "y = df[\"Sentiment\"]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "225f9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sentiments to numerical labels\n",
    "sentiment_map = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "y_train = y_train.map(sentiment_map)\n",
    "y_test = y_test.map(sentiment_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f5d7679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced text preprocessing for financial sentiment\n",
    "def preprocess_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    # Retain numbers and basic punctuation, remove only special characters\n",
    "    text = re.sub(r'http\\S+|[^\\w\\s\\d.,]', '', text)  # Keep numbers, commas, periods\n",
    "    text = re.sub(r'\\s+',' ',text) #collapsing multiple spaces to one space\n",
    "    text = text.strip() #removes white spaces\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    stop_words = set(stopwords.words('english')) - {'not', 'no', 'never', 'very', 'bullish', 'bearish', 'buy', 'sell', 'strong', 'weak', 'profit', 'loss', 'growth'}\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "974eecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raute , headquartered nastola , finland , technology company serving wood product industry worldwide .\n"
     ]
    }
   ],
   "source": [
    "res_1 = preprocess_text(x_train[4256])\n",
    "print(res_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b09d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0da76129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aim increase sale least one fifth 2006 .'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[3443]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e99d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Row 0: 'compa...'\n",
      "Original Row 1: 'inves...'\n",
      "Original Row 2: 'stora...'\n",
      "Original Row 3: 'fiska...'\n",
      "Original Row 4: 'finla...'\n",
      "Original Row 5: 'liqui...'\n",
      "Original Row 6: 'refil...'\n",
      "Original Row 7: 'nd no...'\n",
      "Original Row 8: 'resid...'\n",
      "Original Row 9: 'teles...'\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(x_train.head(10)):\n",
    "    print(f\"Original Row {i}: '{text[:5]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8dfa77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e93037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Augmentation complete. New shapes: (5142,) (5142,)\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "from sklearn.utils import shuffle\n",
    "Augmentation_available = False\n",
    "try:\n",
    "    # Initialize augmentor\n",
    "    aug = naw.SynonymAug(aug_src='wordnet', aug_p=0.3, aug_max=5)\n",
    "\n",
    "    augmented_texts = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    # Augment only underrepresented classes (e.g., 0 and 2)\n",
    "    for label in [0, 2]:\n",
    "        class_samples = x_train[y_train == label]\n",
    "        if label == 0:\n",
    "             mult = 1\n",
    "        else:\n",
    "             mult = 0.5\n",
    "        \n",
    "        for text in class_samples[:int(mult * len(class_samples))]:\n",
    "            try:\n",
    "                new_text = aug.augment(text)\n",
    "                if isinstance(new_text, list):\n",
    "                    new_text = \" \".join(new_text)\n",
    "                augmented_texts.append(new_text)\n",
    "                augmented_labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Augmentation failed for label {label}: {e}\")\n",
    "\n",
    "    # Convert to Series\n",
    "    aug_series = pd.Series(augmented_texts)\n",
    "    label_series = pd.Series(augmented_labels)\n",
    "\n",
    "    # Combine with original training data\n",
    "    x_train = pd.concat([x_train, aug_series], ignore_index=True)\n",
    "    y_train = pd.concat([y_train, label_series], ignore_index=True)\n",
    "\n",
    "    # Shuffle\n",
    "    x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "    print(\"âœ… Augmentation complete. New shapes:\", x_train.shape, y_train.shape)\n",
    "    Augmentation_available = True\n",
    "\n",
    "except Exception as e:\n",
    "        print(f\"Augmentation failed: {e}. Proceeding without augmentation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c4be4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1417    aldata solution , global company engaged suppl...\n",
       "3967    barclays plc lse barc nyse bcs , credit agrico...\n",
       "3236                       payment date march 25 , 2010 .\n",
       "4934               trx long frame up. macd hybridization.\n",
       "5141    finnish investment group neomarkka oyj hel nem...\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1968070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    54.200700\n",
       "2    34.091793\n",
       "0    11.707507\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8fac6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2787\n",
       "2    1753\n",
       "0     602\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41b07bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[2.84717608 0.61499821 0.97775242]\n",
      "{np.int64(0): np.float64(5.694352159468439), np.int64(1): np.float64(0.6149982059562253), np.int64(2): np.float64(1.4666286366229322)}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights with adjustment for imbalance\n",
    "classes = np.unique(y_train)\n",
    "print(classes)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "print(class_weights)\n",
    "# Boost minority classes (negative, neutral) slightly\n",
    "class_weights = class_weights * np.array([2.0, 1.0, 1.5])  # negative, neutral, positive\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bde5792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate Naive Bayes variants with MLflow tracking\n",
    "def train_evaluate_nb(model, model_name, vectorizer, vectorizer_name, is_gaussian=False):\n",
    "    try:\n",
    "        with mlflow.start_run(run_name=f\"{model_name}_{vectorizer_name}_data-aug_02\"):\n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"model_name\", model_name)\n",
    "            mlflow.log_param(\"vectorizer\", vectorizer_name)\n",
    "            mlflow.log_param(\"max_features\", vectorizer.max_features)\n",
    "            mlflow.log_param(\"ngram_range\", vectorizer.ngram_range)\n",
    "            mlflow.log_param(\"max_df\", vectorizer.max_df)\n",
    "            mlflow.log_param(\"augmentation\", Augmentation_available)\n",
    "            \n",
    "            X_train_vec = vectorizer.fit_transform(x_train)\n",
    "            X_test_vec = vectorizer.transform(x_test)\n",
    "            \n",
    "            # Convert to dense array for GaussianNB\n",
    "            if is_gaussian:\n",
    "                X_train_vec = X_train_vec.toarray()\n",
    "                X_test_vec = X_test_vec.toarray()\n",
    "            \n",
    "            # Grid search with reduced parallelization\n",
    "            param_grid = {'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 1.0]} if not is_gaussian else {}\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=3, scoring='balanced_accuracy', n_jobs=1)\n",
    "            grid_search.fit(X_train_vec, y_train)\n",
    "            \n",
    "            # Log best parameters\n",
    "            if not is_gaussian:\n",
    "                mlflow.log_param(\"best_alpha\", grid_search.best_params_.get('alpha', 'N/A'))\n",
    "            \n",
    "            # Best model\n",
    "            best_model = grid_search.best_estimator_\n",
    "            print(f\"\\nBest parameters for {model_name} with {vectorizer_name}: {grid_search.best_params_ if not is_gaussian else 'N/A'}\")\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = best_model.predict(X_test_vec)\n",
    "            \n",
    "            # Evaluate\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "            class_report = classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive'], output_dict=True)\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"balanced_accuracy\", balanced_acc)\n",
    "            for label, metrics in class_report.items():\n",
    "                if isinstance(metrics, dict):\n",
    "                    mlflow.log_metric(f\"f1_score_{label}\", metrics['f1-score'])\n",
    "                    mlflow.log_metric(f\"precision_{label}\", metrics['precision'])\n",
    "                    mlflow.log_metric(f\"recall_{label}\", metrics['recall'])\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.sklearn.log_model(best_model, f\"model_{model_name}_{vectorizer_name}\")\n",
    "            \n",
    "            # Save confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['negative', 'neutral', 'positive'], yticklabels=['negative', 'neutral', 'positive'])\n",
    "            plt.title(f'Confusion Matrix - {model_name} with {vectorizer_name}')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('True')\n",
    "            cm_path = f\"cm_{model_name}_{vectorizer_name}.png\"\n",
    "            plt.savefig(cm_path)\n",
    "            plt.close()\n",
    "            mlflow.log_artifact(cm_path)\n",
    "            os.remove(cm_path)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"\\nResults for {model_name} with {vectorizer_name}:\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred, target_names=['negative', 'neutral', 'positive']))\n",
    "            \n",
    "            return best_model, vectorizer, accuracy\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {model_name} with {vectorizer_name}: {e}\")\n",
    "        return None, None, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "617523d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vectorizers\n",
    "bow_vectorizer = CountVectorizer(max_features=3000, ngram_range=(1, 2), min_df=1, max_df=0.8)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=3000, ngram_range=(1, 2), min_df=1, max_df=0.8)\n",
    "binary_bow_vectorizer = CountVectorizer(max_features=3000, ngram_range=(1, 2), min_df=1, max_df=0.8, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97d7d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate all Naive Bayes variants\n",
    "models = [\n",
    "    (MultinomialNB(class_prior=class_weights), \"MultinomialNB\", False),\n",
    "    (ComplementNB(class_prior=class_weights), \"ComplementNB\", False),\n",
    "    (BernoulliNB(class_prior=class_weights), \"BernoulliNB\", False),\n",
    "    (GaussianNB(), \"GaussianNB\", True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "848c1c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MultinomialNB with Bag of Words...\n",
      "\n",
      "Best parameters for MultinomialNB with Bag of Words: {'alpha': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:21:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/09 13:21:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for MultinomialNB with Bag of Words:\n",
      "Accuracy: 0.6441\n",
      "Balanced Accuracy: 0.6307\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.22      0.58      0.32        76\n",
      "     neutral       0.83      0.64      0.72       697\n",
      "    positive       0.59      0.67      0.63       292\n",
      "\n",
      "    accuracy                           0.64      1065\n",
      "   macro avg       0.55      0.63      0.56      1065\n",
      "weighted avg       0.72      0.64      0.67      1065\n",
      "\n",
      "ðŸƒ View run MultinomialNB_Bag of Words_data-aug_02 at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325/runs/398c376396494c9fbd11d8b2ae421cdf\n",
      "ðŸ§ª View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325\n",
      "\n",
      "Training MultinomialNB with TF-IDF...\n",
      "\n",
      "Best parameters for MultinomialNB with TF-IDF: {'alpha': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:22:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/09 13:22:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for MultinomialNB with TF-IDF:\n",
      "Accuracy: 0.5164\n",
      "Balanced Accuracy: 0.5839\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.18      0.63      0.28        76\n",
      "     neutral       0.84      0.43      0.57       697\n",
      "    positive       0.46      0.69      0.55       292\n",
      "\n",
      "    accuracy                           0.52      1065\n",
      "   macro avg       0.49      0.58      0.47      1065\n",
      "weighted avg       0.69      0.52      0.54      1065\n",
      "\n",
      "ðŸƒ View run MultinomialNB_TF-IDF_data-aug_02 at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325/runs/b723de94698b4734967e9f91347c8cf0\n",
      "ðŸ§ª View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325\n",
      "\n",
      "Training ComplementNB with Bag of Words...\n",
      "\n",
      "Best parameters for ComplementNB with Bag of Words: {'alpha': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:22:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/09 13:22:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ComplementNB with Bag of Words:\n",
      "Accuracy: 0.7333\n",
      "Balanced Accuracy: 0.6828\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.58      0.45        76\n",
      "     neutral       0.85      0.76      0.80       697\n",
      "    positive       0.64      0.71      0.67       292\n",
      "\n",
      "    accuracy                           0.73      1065\n",
      "   macro avg       0.62      0.68      0.64      1065\n",
      "weighted avg       0.76      0.73      0.74      1065\n",
      "\n",
      "ðŸƒ View run ComplementNB_Bag of Words_data-aug_02 at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325/runs/5e5ae2b8def041529617a9a2c7b0fbda\n",
      "ðŸ§ª View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325\n",
      "\n",
      "Training ComplementNB with TF-IDF...\n",
      "\n",
      "Best parameters for ComplementNB with TF-IDF: {'alpha': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:22:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/09 13:22:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for ComplementNB with TF-IDF:\n",
      "Accuracy: 0.7277\n",
      "Balanced Accuracy: 0.6811\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.37      0.59      0.46        76\n",
      "     neutral       0.85      0.76      0.80       697\n",
      "    positive       0.63      0.70      0.66       292\n",
      "\n",
      "    accuracy                           0.73      1065\n",
      "   macro avg       0.62      0.68      0.64      1065\n",
      "weighted avg       0.75      0.73      0.74      1065\n",
      "\n",
      "ðŸƒ View run ComplementNB_TF-IDF_data-aug_02 at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325/runs/f61c08b7b67443c5b5cebc33c01290bc\n",
      "ðŸ§ª View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325\n",
      "\n",
      "Training BernoulliNB with Bag of Words...\n",
      "\n",
      "Best parameters for BernoulliNB with Bag of Words: {'alpha': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:22:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/09 13:22:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for BernoulliNB with Bag of Words:\n",
      "Accuracy: 0.7108\n",
      "Balanced Accuracy: 0.6314\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.27      0.47      0.35        76\n",
      "     neutral       0.83      0.76      0.79       697\n",
      "    positive       0.65      0.66      0.66       292\n",
      "\n",
      "    accuracy                           0.71      1065\n",
      "   macro avg       0.59      0.63      0.60      1065\n",
      "weighted avg       0.74      0.71      0.72      1065\n",
      "\n",
      "ðŸƒ View run BernoulliNB_Bag of Words_data-aug_02 at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325/runs/23698747c20942269c20f16992426544\n",
      "ðŸ§ª View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325\n",
      "\n",
      "Training BernoulliNB with TF-IDF...\n",
      "\n",
      "Best parameters for BernoulliNB with TF-IDF: {'alpha': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:22:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/09 13:22:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for BernoulliNB with TF-IDF:\n",
      "Accuracy: 0.7108\n",
      "Balanced Accuracy: 0.6314\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.27      0.47      0.35        76\n",
      "     neutral       0.83      0.76      0.79       697\n",
      "    positive       0.65      0.66      0.66       292\n",
      "\n",
      "    accuracy                           0.71      1065\n",
      "   macro avg       0.59      0.63      0.60      1065\n",
      "weighted avg       0.74      0.71      0.72      1065\n",
      "\n",
      "ðŸƒ View run BernoulliNB_TF-IDF_data-aug_02 at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325/runs/7eea78ff95764006a28d895f85e5bbc6\n",
      "ðŸ§ª View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325\n",
      "\n",
      "Training GaussianNB with Bag of Words...\n",
      "\n",
      "Best parameters for GaussianNB with Bag of Words: N/A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:23:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/09 13:23:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for GaussianNB with Bag of Words:\n",
      "Accuracy: 0.4460\n",
      "Balanced Accuracy: 0.4499\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.12      0.26      0.17        76\n",
      "     neutral       0.76      0.34      0.47       697\n",
      "    positive       0.37      0.75      0.49       292\n",
      "\n",
      "    accuracy                           0.45      1065\n",
      "   macro avg       0.42      0.45      0.38      1065\n",
      "weighted avg       0.61      0.45      0.45      1065\n",
      "\n",
      "ðŸƒ View run GaussianNB_Bag of Words_data-aug_02 at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325/runs/f3d63a50d6f04761a129a2e2fdd33fe8\n",
      "ðŸ§ª View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325\n",
      "\n",
      "Training GaussianNB with TF-IDF...\n",
      "\n",
      "Best parameters for GaussianNB with TF-IDF: N/A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:23:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/09/09 13:23:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for GaussianNB with TF-IDF:\n",
      "Accuracy: 0.4629\n",
      "Balanced Accuracy: 0.4440\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.12      0.25      0.16        76\n",
      "     neutral       0.75      0.39      0.51       697\n",
      "    positive       0.37      0.69      0.48       292\n",
      "\n",
      "    accuracy                           0.46      1065\n",
      "   macro avg       0.41      0.44      0.39      1065\n",
      "weighted avg       0.60      0.46      0.48      1065\n",
      "\n",
      "ðŸƒ View run GaussianNB_TF-IDF_data-aug_02 at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325/runs/393e635e38ff4d0aae5f1e68ac93b16e\n",
      "ðŸ§ª View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/639483181163671325\n"
     ]
    }
   ],
   "source": [
    "# Run for BoW and TF-IDF\n",
    "best_model, best_vectorizer, best_accuracy = None, None, 0\n",
    "for model, model_name, is_gaussian in models:\n",
    "    print(f\"\\nTraining {model_name} with Bag of Words...\")\n",
    "    nb_bow, bow_vec, acc_bow = train_evaluate_nb(model, model_name, bow_vectorizer, \"Bag of Words\", is_gaussian)\n",
    "    if nb_bow and acc_bow > best_accuracy:\n",
    "        best_model, best_vectorizer, best_accuracy = nb_bow, bow_vec, acc_bow\n",
    "    \n",
    "    print(f\"\\nTraining {model_name} with TF-IDF...\")\n",
    "    nb_tfidf, tfidf_vec, acc_tfidf = train_evaluate_nb(model, model_name, tfidf_vectorizer, \"TF-IDF\", is_gaussian)\n",
    "    if nb_tfidf and acc_tfidf > best_accuracy:\n",
    "        best_model, best_vectorizer, best_accuracy = nb_tfidf, tfidf_vec, acc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c3b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_ops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
