{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13dfcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e282197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting tracking \n",
    "mlflow.set_tracking_uri(\"http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff60c0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name :baseline_ML_model and id:408458959843314322\n",
      "Experiment name :Navie_bayes_experiment and id:639483181163671325\n",
      "Experiment name :Default and id:0\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient \n",
    "client = MlflowClient()\n",
    "\n",
    "# Get all experiments (returns List[Experiment])\n",
    "experiments_id = client.search_experiments()\n",
    "\n",
    "for exp in experiments_id:\n",
    "    print(f\"Experiment name :{exp.name} and id:{exp.experiment_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02fc0a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 13:46:56 INFO mlflow.tracking.fluent: Experiment with name 'baseline_ML_model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://s3bucmlflow/408458959843314322', creation_time=1757405817706, experiment_id='408458959843314322', last_update_time=1757405817706, lifecycle_stage='active', name='baseline_ML_model', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name=\"baseline_ML_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c92530e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "0     The GeoSolutions technology will leverage Bene...   neutral\n",
       "1     $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2     For the last quarter of 2010 , Componenta 's n...   neutral\n",
       "3     According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4     The Swedish buyout firm has sold its remaining...   neutral\n",
       "...                                                 ...       ...\n",
       "5837  RISING costs have forced packaging producer Hu...   neutral\n",
       "5838  Nordic Walking was first used as a summer trai...   neutral\n",
       "5839  According shipping company Viking Line , the E...   neutral\n",
       "5840  In the building and home improvement trade , s...  negative\n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...   neutral\n",
       "\n",
       "[5842 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/root/mlops_projects/FinancialSentiment_prediction/Datasets/Financial_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090f10ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5842, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f95a754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(520)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d6ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c10c961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords,wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d1b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # Retain numbers and basic punctuation, remove only special characters\n",
    "    text = re.sub(r'http\\S+|[^\\w\\s.]', '', text)  # Keep numbers, commas, periods\n",
    "    text = re.sub(r'\\s+',' ',text) #collapsing multiple spaces to one space\n",
    "    #text = text.strip() #removes white spaces\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    stop_words = set(stopwords.words('english')) - {'not', 'no', 'never', 'very', 'bullish', 'bearish', 'buy', 'sell', 'strong', 'weak', 'profit', 'loss', 'growth'}\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a783e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentence\"] = df[\"Sentence\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a96587f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"Sentence\"]\n",
    "y = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23572266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_con(data):\n",
    "    res = data.map(lambda x: 1 if x == \"positive\" else (0 if x == \"neutral\" else -1))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d31933ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_con(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d891534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1      -1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "5835    0\n",
      "5836    0\n",
      "5838    0\n",
      "5839    0\n",
      "5841    0\n",
      "Name: Sentiment, Length: 5322, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cef1d71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5322,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaa3b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bfb0b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1], shape=(3991,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a866b3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id for baseline_ML_model is :408458959843314322\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"baseline_ML_model\"\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(name=experiment_name)\n",
    "    experiment_Id = experiment.experiment_id\n",
    "    print(f\"experiment_id for {experiment_name} is :{experiment_Id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ded91c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model(model, model_name,experiment_id, vectorizer_type):\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=f\"{model_name}-{vectorizer_type}\"):\n",
    "\n",
    "        # Vectorization\n",
    "        if vectorizer_type == \"bow\":\n",
    "            vectorizer = CountVectorizer()\n",
    "        elif vectorizer_type == \"tfidf\":\n",
    "            vectorizer = TfidfVectorizer()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid vectorizer type\")\n",
    "\n",
    "        X_train_vec = vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(X_train_vec, y_train)\n",
    "        y_pred = model.predict(X_test_vec)\n",
    "\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Manual logging\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_param(\"vectorizer\", vectorizer_type)\n",
    "        mlflow.log_param(\"vectorizer_vocab_size\", len(vectorizer.vocabulary_))\n",
    "        if hasattr(model, \"get_params\"):\n",
    "            for k, v in model.get_params().items():\n",
    "                mlflow.log_param(k, v)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        # Signature\n",
    "        X_sample = X_train_vec[:2]\n",
    "        y_sample = model.predict(X_sample)\n",
    "        signature = infer_signature(X_sample, y_sample)\n",
    "\n",
    "        # Save model and vectorizer\n",
    "        mlflow.sklearn.log_model(model, name=\"model\", signature=signature,input_example=X_sample)\n",
    "        mlflow.sklearn.log_model(vectorizer, name=\"vectorizer\")\n",
    "\n",
    "        print(f\"{model_name} ({vectorizer_type}) — Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8367091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 14:00:50 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "\u001b[31m2025/09/09 14:00:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression (tfidf) — Accuracy: 0.8062, F1 Score: 0.7817\n",
      "🏃 View run LogisticRegression-tfidf at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322/runs/eb8a271d564c47faa32a81eada455677\n",
      "🧪 View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model(LogisticRegression(max_iter=500),\"LogisticRegression\",experiment_Id,\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fe0a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 14:01:16 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "\u001b[31m2025/09/09 14:01:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression (bow) — Accuracy: 0.8535, F1 Score: 0.8449\n",
      "🏃 View run LogisticRegression-bow at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322/runs/4ed1f70b9ab44d888afefb7efe2b6c6c\n",
      "🧪 View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model(LogisticRegression(max_iter=500), \"LogisticRegression\",experiment_Id,\"bow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb8d82a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model_with_tuning(model_class, model_name, vectorizer_type,\n",
    "                                    X_train, X_test, y_train, y_test,\n",
    "                                    experiment_id, param_distributions,\n",
    "                                    n_iter_search=10, cv_folds=3, scoring_metric='f1_weighted'):\n",
    "    \"\"\"\n",
    "    Trains and logs a model after performing RandomizedSearchCV for hyperparameter tuning.\n",
    "    The best model from the search is logged.\n",
    "    \"\"\"\n",
    "    run_name_prefix = f\"{model_name}-{vectorizer_type}-Tuning\"\n",
    "\n",
    "    X_train = X_train.astype(str).fillna('')\n",
    "    X_test = X_test.astype(str).fillna('')\n",
    "\n",
    "    if model_class == XGBClassifier: #as classifier not accept negative labels\n",
    "        y_train = y_train.map({0:0,1:1,-1:2})\n",
    "        y_test  = y_test.map({0:0,1:1,-1:2})\n",
    "\n",
    "    # Define the base vectorizer based on type\n",
    "    if vectorizer_type == \"bow\":\n",
    "        vectorizer_instance = CountVectorizer()\n",
    "    elif vectorizer_type == \"tfidf\":\n",
    "        vectorizer_instance = TfidfVectorizer()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid vectorizer type\")\n",
    "\n",
    "    # Instantiate the classifier\n",
    "    if model_class == XGBClassifier:\n",
    "        classifier_instance = XGBClassifier(\n",
    "            #use_label_encoder=False,  # Recommended to suppress future warnings\n",
    "            eval_metric='mlogloss',   # Multi-class logloss for multi-class classification\n",
    "            objective='multi:softmax', # For direct class predictions\n",
    "            num_class=len(y.unique()), # Important: Set number of classes\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        classifier_instance = model_class(random_state=42) # Setting random_state for reproducibility\n",
    "\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer_instance),\n",
    "        ('classifier', classifier_instance)\n",
    "    ])\n",
    "\n",
    "    # Initialize RandomizedSearchCV\n",
    "    # We pass the pipeline here, and the param_distributions should be prefixed\n",
    "    # e.g., 'classifier__n_estimators'\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter_search,\n",
    "        cv=cv_folds,\n",
    "        scoring=scoring_metric,\n",
    "        random_state=42, # For reproducible search results\n",
    "        n_jobs=4, # Use all available CPU cores for parallel processing\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"\\nStarting RandomizedSearchCV for {model_name} with {vectorizer_type}...\")\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model found by the search\n",
    "    best_pipeline = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "    best_score = random_search.best_score_\n",
    "\n",
    "    # Make predictions with the best model\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate final metrics on the test set\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Start MLflow run for logging the BEST model from the search\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=f\"{run_name_prefix}-BestModel\"):\n",
    "\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"vectorizer_type\", vectorizer_type)\n",
    "        mlflow.log_param(\"tuning_method\", \"RandomizedSearchCV\")\n",
    "        mlflow.log_param(\"n_iter_search\", n_iter_search)\n",
    "        mlflow.log_param(\"cv_folds\", cv_folds)\n",
    "        mlflow.log_param(\"scoring_metric\", scoring_metric)\n",
    "\n",
    "        # Log all best parameters found by the search\n",
    "        for k, v in best_params.items():\n",
    "            mlflow.log_param(k, v)\n",
    "\n",
    "        # Log metrics (best CV score and test set performance)\n",
    "        mlflow.log_metric(f\"best_cv_{scoring_metric}\", best_score)\n",
    "        mlflow.log_metric(\"test_accuracy\", acc)\n",
    "        mlflow.log_metric(\"test_f1_score_weighted\", f1)\n",
    "\n",
    "         # Directly log the full classification report as a text file\n",
    "        full_report_str = classification_report(y_test, y_pred)\n",
    "        mlflow.log_text(full_report_str, \"classification_report.txt\")\n",
    "\n",
    "        print(\"\\nClassification Report:\\n\", full_report_str)\n",
    "\n",
    "\n",
    "\n",
    "        # Log vectorizer specific parameters (from the best pipeline's vectorizer)\n",
    "        best_vectorizer = best_pipeline.named_steps['vectorizer']\n",
    "        mlflow.log_param(\"vectorizer_vocab_size\", len(best_vectorizer.vocabulary_))\n",
    "        if hasattr(best_vectorizer, \"get_params\"):\n",
    "            for k, v in best_vectorizer.get_params().items():\n",
    "                # Filter out parameters that aren't typically interesting to log at top level\n",
    "                if not (k.startswith(\"input\") or k.startswith(\"dtype\")):\n",
    "                    mlflow.log_param(f\"vectorizer_{k}\", v)\n",
    "\n",
    "\n",
    "        # Log the entire best pipeline\n",
    "        # Signature for the entire pipeline: Input is raw text, Output is prediction\n",
    "        pipeline_input_example = X_train[:2].astype('str').fillna('').to_list() # Ensure input example is raw text\n",
    "        pipeline_output_example = best_pipeline.predict(pipeline_input_example)\n",
    "        pipeline_signature = infer_signature(pipeline_input_example, pipeline_output_example)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_pipeline,\n",
    "            name= \"text_classification_pipeline\",\n",
    "            signature=pipeline_signature,\n",
    "            input_example=pipeline_input_example\n",
    "        )\n",
    "\n",
    "        print(f\"\\n--- Best Model from Tuning ---\")\n",
    "        print(f\"Model: {model_name}, Vectorizer: {vectorizer_type}\")\n",
    "        print(f\"Best CV Score ({scoring_metric}): {best_score:.4f}\")\n",
    "        print(f\"Test Accuracy: {acc:.4f}, Test F1 Score (weighted): {f1:.4f}\")\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"MLflow Run ID: {mlflow.active_run().info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54236ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_example = X_train[:2].astype('str').fillna('').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17a9ed31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipeline_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc3fa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest parameters \n",
    "rf_param_distributions_bow = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 1.0, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'classifier__n_estimators': [100, 200, 300, 500],\n",
    "    'classifier__max_depth': [10, 20, 30, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rf_param_distributions_tfidf = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 1.0, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__use_idf': [True, False],\n",
    "    'classifier__n_estimators': [100, 250, 400],\n",
    "    'classifier__max_depth': [15, 25, None],\n",
    "    'classifier__min_samples_split': [2, 5, 8],\n",
    "    'classifier__min_samples_leaf': [1, 2, 3],\n",
    "    'classifier__max_features': ['sqrt', 0.6, 0.8],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a58f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_distributions_tfidf = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 1.0, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__use_idf': [True, False], # Important for TF-IDF\n",
    "    'classifier__C': np.logspace(-3, 2, 6), # Example: 0.001, 0.01, 0.1, 1, 10, 100\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear', 'saga'], # Solvers supporting l1/l2\n",
    "    'classifier__max_iter': [100, 200, 500], # Increase if convergence warnings appear\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "lr_param_distributions_bow = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 1.0, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'classifier__C': np.logspace(-4, 3, 8), # Broader range for C\n",
    "    'classifier__penalty': ['l2'], # Common choice for Logistic Regression\n",
    "    'classifier__solver': ['lbfgs', 'newton-cg', 'sag'], # Solvers supporting only l2\n",
    "    'classifier__max_iter': [100, 300, 1000],\n",
    "    'classifier__class_weight': [None, 'balanced']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1765f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_distributions_bow = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 0.99, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__subsample': [0.7, 0.9],\n",
    "    'classifier__colsample_bytree': [0.7, 0.9],\n",
    "    'classifier__gamma': [0, 0.1, 0.2] # Min loss reduction to make a split\n",
    "}\n",
    "\n",
    "xgb_param_distributions_tf_idf = {\n",
    "    'vectorizer__max_df': np.arange(0.7, 0.99, 0.05),\n",
    "    'vectorizer__min_df': [1, 5, 10],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__use_idf': [True, False], # Important for TF-IDF\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__subsample': [0.7, 0.9],\n",
    "    'classifier__colsample_bytree': [0.7, 0.9],\n",
    "    'classifier__gamma': [0, 0.1, 0.2] # Min loss reduction to make a split\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ff2ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Random Forest Tuning ---\n",
      "\n",
      "Starting RandomizedSearchCV for RandomForestClassifier with bow...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.37      0.52        94\n",
      "           0       0.84      0.97      0.90       871\n",
      "           1       0.94      0.73      0.82       366\n",
      "\n",
      "    accuracy                           0.86      1331\n",
      "   macro avg       0.88      0.69      0.75      1331\n",
      "weighted avg       0.87      0.86      0.85      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 14:15:02 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"nq got hit hard lower look li.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: RandomForestClassifier, Vectorizer: bow\n",
      "Best CV Score (f1_weighted): 0.8349\n",
      "Test Accuracy: 0.8640, Test F1 Score (weighted): 0.8536\n",
      "Best Parameters: {'vectorizer__ngram_range': (1, 1), 'vectorizer__min_df': 1, 'vectorizer__max_df': np.float64(0.9500000000000002), 'classifier__n_estimators': 300, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 0.5, 'classifier__max_depth': 20, 'classifier__class_weight': None}\n",
      "MLflow Run ID: 8f0e625a42f04c1db70b05d169efd01d\n",
      "🏃 View run RandomForestClassifier-bow-Tuning-BestModel at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322/runs/8f0e625a42f04c1db70b05d169efd01d\n",
      "🧪 View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Running Random Forest Tuning ---\")\n",
    "train_and_log_model_with_tuning(\n",
    "    model_class=RandomForestClassifier,\n",
    "    model_name=\"RandomForestClassifier\",\n",
    "    vectorizer_type=\"bow\",\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=rf_param_distributions_bow,\n",
    "    n_iter_search=5, \n",
    "    cv_folds=2,      \n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b48c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for RandomForestClassifier with tfidf...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.37      0.53        94\n",
      "           0       0.84      0.97      0.90       871\n",
      "           1       0.93      0.73      0.82       366\n",
      "\n",
      "    accuracy                           0.86      1331\n",
      "   macro avg       0.89      0.69      0.75      1331\n",
      "weighted avg       0.87      0.86      0.85      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 14:17:15 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"nq got hit hard lower look li.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: RandomForestClassifier, Vectorizer: tfidf\n",
      "Best CV Score (f1_weighted): 0.8369\n",
      "Test Accuracy: 0.8640, Test F1 Score (weighted): 0.8536\n",
      "Best Parameters: {'vectorizer__use_idf': True, 'vectorizer__ngram_range': (1, 1), 'vectorizer__min_df': 5, 'vectorizer__max_df': np.float64(0.8), 'classifier__n_estimators': 400, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 3, 'classifier__max_features': 0.6, 'classifier__max_depth': 25, 'classifier__class_weight': None}\n",
      "MLflow Run ID: a4bef01702df4df596617229bfe0cd58\n",
      "🏃 View run RandomForestClassifier-tfidf-Tuning-BestModel at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322/runs/a4bef01702df4df596617229bfe0cd58\n",
      "🧪 View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=RandomForestClassifier,\n",
    "    model_name=\"RandomForestClassifier\",\n",
    "    vectorizer_type=\"tfidf\",\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=rf_param_distributions_tfidf,\n",
    "    n_iter_search=5,\n",
    "    cv_folds=2,\n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5eed8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for LogisticRegression with bow...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.37      0.50        94\n",
      "           0       0.83      0.96      0.89       871\n",
      "           1       0.91      0.69      0.78       366\n",
      "\n",
      "    accuracy                           0.84      1331\n",
      "   macro avg       0.83      0.67      0.72      1331\n",
      "weighted avg       0.85      0.84      0.83      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 14:18:13 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"nq got hit hard lower look li.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: LogisticRegression, Vectorizer: bow\n",
      "Best CV Score (f1_weighted): 0.7786\n",
      "Test Accuracy: 0.8430, Test F1 Score (weighted): 0.8323\n",
      "Best Parameters: {'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 1, 'vectorizer__max_df': np.float64(0.7), 'classifier__solver': 'newton-cg', 'classifier__penalty': 'l2', 'classifier__max_iter': 100, 'classifier__class_weight': None, 'classifier__C': np.float64(10.0)}\n",
      "MLflow Run ID: e73482521b374aeaa659ff657c201ed8\n",
      "🏃 View run LogisticRegression-bow-Tuning-BestModel at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322/runs/e73482521b374aeaa659ff657c201ed8\n",
      "🧪 View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=LogisticRegression,\n",
    "    model_name=\"LogisticRegression\",\n",
    "    vectorizer_type=\"bow\",\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=lr_param_distributions_bow,\n",
    "    n_iter_search=5,\n",
    "    cv_folds=2,\n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5892dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for LogisticRegression with tfidf...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/root/mlops_projects/FinancialSentiment_prediction/fin_ops/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.43      0.53        94\n",
      "           0       0.86      0.91      0.88       871\n",
      "           1       0.80      0.77      0.78       366\n",
      "\n",
      "    accuracy                           0.84      1331\n",
      "   macro avg       0.78      0.70      0.73      1331\n",
      "weighted avg       0.83      0.84      0.83      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 14:41:24 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"nq got hit hard lower look li.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: LogisticRegression, Vectorizer: tfidf\n",
      "Best CV Score (f1_weighted): 0.7882\n",
      "Test Accuracy: 0.8355, Test F1 Score (weighted): 0.8301\n",
      "Best Parameters: {'vectorizer__use_idf': True, 'vectorizer__ngram_range': (1, 1), 'vectorizer__min_df': 1, 'vectorizer__max_df': np.float64(0.8500000000000001), 'classifier__solver': 'liblinear', 'classifier__penalty': 'l2', 'classifier__max_iter': 500, 'classifier__class_weight': 'balanced', 'classifier__C': np.float64(100.0)}\n",
      "MLflow Run ID: 8c166b8b9e9844459516180c7fb7f251\n",
      "🏃 View run LogisticRegression-tfidf-Tuning-BestModel at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322/runs/8c166b8b9e9844459516180c7fb7f251\n",
      "🧪 View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=LogisticRegression,\n",
    "    model_name=\"LogisticRegression\",\n",
    "    vectorizer_type=\"tfidf\",\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_test=X_test, y_test=y_test,\n",
    "    experiment_id=experiment_Id,\n",
    "    param_distributions=lr_param_distributions_tfidf,\n",
    "    n_iter_search=5,\n",
    "    cv_folds=2,\n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fddad507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X_train elements: <class 'str'>\n",
      "Sample of X_train: 196     nq got hit hard lower look like ha found suppo...\n",
      "2765    company presently examining whether project wo...\n",
      "4350    meeting glisten shareholder vote bid held 12 m...\n",
      "4226       value confirmed aircraft order total eur 2bn .\n",
      "1402    finnish financial software solution developer ...\n",
      "Name: Sentence, dtype: object\n",
      "Check for non-string types in X_train:\n",
      "non string elements Series([], Name: Sentence, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of X_train elements:\", type(X_train.iloc[0])) # Check first element type\n",
    "print(\"Sample of X_train:\", X_train.head())\n",
    "print(\"Check for non-string types in X_train:\")\n",
    "# This will check if any element in the Series is not a string\n",
    "non_string_elements = X_train[X_train.apply(lambda x: not isinstance(x, str))]\n",
    "if  non_string_elements.any():\n",
    "    print(\"Found non-string elements in X_train:\", non_string_elements)\n",
    "else:\n",
    "    print(\"non string elements\", non_string_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53dfcc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for XGBoostClassifier with bow...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       871\n",
      "           1       0.95      0.71      0.81       366\n",
      "           2       0.80      0.39      0.53        94\n",
      "\n",
      "    accuracy                           0.86      1331\n",
      "   macro avg       0.86      0.69      0.75      1331\n",
      "weighted avg       0.87      0.86      0.85      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 14:53:49 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"nq got hit hard lower look li.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: XGBoostClassifier, Vectorizer: bow\n",
      "Best CV Score (f1_weighted): 0.8326\n",
      "Test Accuracy: 0.8603, Test F1 Score (weighted): 0.8506\n",
      "Best Parameters: {'vectorizer__ngram_range': (1, 1), 'vectorizer__min_df': 1, 'vectorizer__max_df': np.float64(0.8500000000000001), 'classifier__subsample': 0.7, 'classifier__n_estimators': 200, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.05, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.9}\n",
      "MLflow Run ID: 44b850dd11e8492ab79ee6de8d217523\n",
      "🏃 View run XGBoostClassifier-bow-Tuning-BestModel at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322/runs/44b850dd11e8492ab79ee6de8d217523\n",
      "🧪 View experiment at: http://ec2-65-0-103-88.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=XGBClassifier, # Pass the class itself\n",
    "    model_name=\"XGBoostClassifier\",\n",
    "    vectorizer_type=\"bow\",\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    experiment_id=experiment_Id, # Use the obtained experiment_id\n",
    "    param_distributions= xgb_param_distributions_bow, #param_distributions,\n",
    "    n_iter_search=5, \n",
    "    cv_folds=2,      \n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac3dc943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting RandomizedSearchCV for XGBoostClassifier with tfidf...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       871\n",
      "           1       0.95      0.74      0.83       366\n",
      "           2       0.81      0.47      0.59        94\n",
      "\n",
      "    accuracy                           0.87      1331\n",
      "   macro avg       0.87      0.73      0.78      1331\n",
      "weighted avg       0.88      0.87      0.87      1331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/09 15:49:22 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    \"nq got hit hard lower look li.... Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'int' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Best Model from Tuning ---\n",
      "Model: XGBoostClassifier, Vectorizer: tfidf\n",
      "Best CV Score (f1_weighted): 0.8246\n",
      "Test Accuracy: 0.8730, Test F1 Score (weighted): 0.8660\n",
      "Best Parameters: {'vectorizer__use_idf': False, 'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 10, 'vectorizer__max_df': np.float64(0.8500000000000001), 'classifier__subsample': 0.9, 'classifier__n_estimators': 200, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.05, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.9}\n",
      "MLflow Run ID: 97a7578c949846c1b45fb1929516b327\n",
      "🏃 View run XGBoostClassifier-tfidf-Tuning-BestModel at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322/runs/97a7578c949846c1b45fb1929516b327\n",
      "🧪 View experiment at: http://ec2-43-205-211-96.ap-south-1.compute.amazonaws.com:5000/#/experiments/408458959843314322\n"
     ]
    }
   ],
   "source": [
    "train_and_log_model_with_tuning(\n",
    "    model_class=XGBClassifier, \n",
    "    model_name=\"XGBoostClassifier\",\n",
    "    vectorizer_type=\"tfidf\",\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test,\n",
    "    experiment_id=experiment_Id, # Use the obtained experiment_id\n",
    "    param_distributions= xgb_param_distributions_tf_idf, #param_distributions,\n",
    "    n_iter_search=5, # Reduced for quick demo, increase for real tuning\n",
    "    cv_folds=2,      # Reduced for quick demo\n",
    "    scoring_metric='f1_weighted'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_ops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
